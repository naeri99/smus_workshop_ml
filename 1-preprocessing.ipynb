{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b098cad-43ae-4044-a071-e115cadb0501",
   "metadata": {},
   "source": [
    "# [Lab1] ë°ì´í„° ì „ì²˜ë¦¬ with SageMaker Processing\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” SageMaker Processing Jobì„ ì‚¬ìš©í•˜ì—¬ ì€í–‰ ë§ˆì¼€íŒ… ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ë‚´ìš©\n",
    "- SageMaker Processing Job ì„¤ì •\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±\n",
    "- MLflowë¥¼ í†µí•œ ì‹¤í—˜ ì¶”ì \n",
    "- ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ S3ì— ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë³€ìˆ˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "0bec468a-a0d5-4084-a858-86b35d8d9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ì €ì¥í•œ ë³€ìˆ˜ë“¤ ë¡œë“œ\n",
    "%store -r\n",
    "\n",
    "print(\"âœ… ì €ì¥ëœ ë³€ìˆ˜ë“¤ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"   - S3 ë²„í‚·: {bucket}\")\n",
    "print(f\"   - S3 í”„ë¦¬í”½ìŠ¤: {prefix}\")\n",
    "print(f\"   - ë¦¬ì „: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "f78db854-61ee-45ce-9a8a-d3e68cff2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker_studio import Project\n",
    "\n",
    "# AWS ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "boto_session = boto3.Session()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e4246-cc09-450a-8b4b-5636eccea2b5",
   "metadata": {},
   "source": [
    "## 2. ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„\n",
    "\n",
    "SageMaker Processing Jobì—ì„œ ì‹¤í–‰ë  ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "create-processing-dir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "!mkdir -p processing/requirements\n",
    "\n",
    "print(\"âœ… ì²˜ë¦¬ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "requirements-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile processing/requirements/requirements.txt\n",
    "mlflow==2.13.2\n",
    "sagemaker-mlflow==0.1.0\n",
    "pandas\n",
    "numpy\n",
    "scikit-learn\n",
    "sagemaker-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "preprocessing-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile processing/preprocessing.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Requirements ì„¤ì¹˜\n",
    "def install_requirements():\n",
    "    requirements_path = '/opt/ml/processing/input/code/requirements.txt'\n",
    "    if os.path.exists(requirements_path):\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', requirements_path])\n",
    "            print(\"Requirements installed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error installing requirements: {e}\")\n",
    "            # í•„ìˆ˜ íŒ¨í‚¤ì§€ë§Œ ê°œë³„ ì„¤ì¹˜\n",
    "            essential_packages = ['mlflow==2.13.2', 'sagemaker-mlflow==0.1.0', 'pandas', 'numpy', 'scikit-learn']\n",
    "            for package in essential_packages:\n",
    "                try:\n",
    "                    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "                except:\n",
    "                    print(f\"Failed to install {package}\")\n",
    "    else:\n",
    "        print(f\"Requirements file not found at {requirements_path}\")\n",
    "\n",
    "# Requirements ì„¤ì¹˜ ì‹¤í–‰\n",
    "install_requirements()\n",
    "\n",
    "import mlflow\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# MLflow ì„¤ì • - í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "mlflow_arn = os.getenv('MLFLOW_TRACKING_ARN')\n",
    "mlflow_run_id = os.getenv('MLFLOW_RUN_ID')\n",
    "user_profile_name = os.getenv('USER')\n",
    "domain_id = os.getenv('DOMAIN_ID')\n",
    "\n",
    "print(f\"MLflow ARN: {mlflow_arn}\")\n",
    "print(f\"Run ID: {mlflow_run_id}\")\n",
    "print(f\"User: {user_profile_name}\")\n",
    "print(f\"Domain ID: {domain_id}\")\n",
    "\n",
    "def _parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bank-additional-full.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def process_data(args):\n",
    "    \"\"\"ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\"\"\"\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    df = pd.read_csv(os.path.join(args.filepath, args.filename))\n",
    "    print(f\"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "    \n",
    "    # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    # 1. ì (.)ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½\n",
    "    df = df.replace(regex=r'\\.', value='_')\n",
    "    df = df.replace(regex=r'\\_$', value='')\n",
    "    \n",
    "    # 2. ìƒˆë¡œìš´ íŠ¹ì„± ì¶”ê°€\n",
    "    df[\"no_previous_contact\"] = (df[\"pdays\"] == 999).astype(int)\n",
    "    df[\"not_working\"] = df[\"job\"].isin([\"student\", \"retired\", \"unemployed\"]).astype(int)\n",
    "    \n",
    "    # 3. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°\n",
    "    df = df.drop(['duration', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'], axis=1)\n",
    "    \n",
    "    # 4. ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©\n",
    "    df = pd.get_dummies(df)\n",
    "    print(f\"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "    \n",
    "    # 5. í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        df.sample(frac=1, random_state=42), \n",
    "        [int(0.7 * len(df)), int(0.9 * len(df))]\n",
    "    )\n",
    "    \n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {train_data.shape}\")\n",
    "    print(f\"ê²€ì¦ ë°ì´í„°: {validation_data.shape}\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_data.shape}\")\n",
    "    \n",
    "    return train_data, validation_data, test_data, df\n",
    "\n",
    "def save_data(train_data, validation_data, test_data, df, output_path):\n",
    "    \"\"\"ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥\"\"\"\n",
    "    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    for subdir in ['train', 'validation', 'test', 'baseline']:\n",
    "        os.makedirs(os.path.join(output_path, subdir), exist_ok=True)\n",
    "    \n",
    "    # í›ˆë ¨ ë°ì´í„° ì €ì¥ (íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)\n",
    "    pd.concat([train_data['y_yes'], train_data.drop(['y_yes','y_no'], axis=1)], axis=1).to_csv(\n",
    "        os.path.join(output_path, 'train/train.csv'), index=False, header=False)\n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„° ì €ì¥\n",
    "    pd.concat([validation_data['y_yes'], validation_data.drop(['y_yes','y_no'], axis=1)], axis=1).to_csv(\n",
    "        os.path.join(output_path, 'validation/validation.csv'), index=False, header=False)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥ (X, y ë¶„ë¦¬)\n",
    "    test_data['y_yes'].to_csv(os.path.join(output_path, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop(['y_yes','y_no'], axis=1).to_csv(\n",
    "        os.path.join(output_path, 'test/test_x.csv'), index=False, header=False)\n",
    "    \n",
    "    # ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„° ì €ì¥\n",
    "    baseline_path = os.path.join(output_path, 'baseline/baseline.csv')\n",
    "    df.drop(['y_yes','y_no'], axis=1).to_csv(baseline_path, index=False, header=False)\n",
    "    \n",
    "    return baseline_path\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    # MLflow ì„¤ì •\n",
    "    if mlflow_arn:\n",
    "        mlflow.set_tracking_uri(mlflow_arn)\n",
    "        mlflow.autolog()\n",
    "        \n",
    "        try:\n",
    "            # ê¸°ì¡´ ì‹¤í–‰ ID ì‚¬ìš© ë˜ëŠ” ìƒˆ ì‹¤í–‰ ìƒì„±\n",
    "            if mlflow_run_id:\n",
    "                try:\n",
    "                    client = mlflow.MlflowClient()\n",
    "                    run_info = client.get_run(mlflow_run_id).info\n",
    "                    run_context = mlflow.start_run(run_id=mlflow_run_id)\n",
    "                    print(f\"ê¸°ì¡´ ì‹¤í–‰ ì—°ê²°: {mlflow_run_id}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"ìƒˆ ì‹¤í–‰ ìƒì„±: {e}\")\n",
    "                    run_context = mlflow.start_run()\n",
    "            else:\n",
    "                run_context = mlflow.start_run()\n",
    "                \n",
    "            with run_context:\n",
    "                # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "                train_data, validation_data, test_data, df = process_data(args)\n",
    "                \n",
    "                # MLflowì— íŒŒë¼ë¯¸í„° ë¡œê¹…\n",
    "                mlflow.log_params({\n",
    "                    \"train_shape\": train_data.shape,\n",
    "                    \"validate_shape\": validation_data.shape,\n",
    "                    \"test_shape\": test_data.shape,\n",
    "                    \"total_features\": df.shape[1] - 2  # y_yes, y_no ì œì™¸\n",
    "                })\n",
    "                \n",
    "                # íƒœê·¸ ì„¤ì •\n",
    "                mlflow.set_tags({\n",
    "                    'mlflow.user': user_profile_name,\n",
    "                    'mlflow.source.type': 'PROCESSING_JOB',\n",
    "                    'sagemaker.domain_id': domain_id,\n",
    "                    'processing.stage': 'data_preprocessing'\n",
    "                })\n",
    "                \n",
    "                # ë°ì´í„° ì €ì¥\n",
    "                baseline_path = save_data(train_data, validation_data, test_data, df, args.outputpath)\n",
    "                \n",
    "                # MLflowì— ì•„í‹°íŒ©íŠ¸ ë¡œê¹…\n",
    "                mlflow.log_artifact(local_path=baseline_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"MLflow ì˜¤ë¥˜: {e}\")\n",
    "            # MLflow ì—†ì´ ë°ì´í„° ì²˜ë¦¬\n",
    "            train_data, validation_data, test_data, df = process_data(args)\n",
    "            save_data(train_data, validation_data, test_data, df, args.outputpath)\n",
    "    else:\n",
    "        print(\"MLflow ARNì´ ì—†ìŠµë‹ˆë‹¤. MLflow ì—†ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "        train_data, validation_data, test_data, df = process_data(args)\n",
    "        save_data(train_data, validation_data, test_data, df, args.outputpath)\n",
    "    \n",
    "    print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759076db-8655-4849-8688-e6013641e7e8",
   "metadata": {},
   "source": [
    "## 3. ì…ë ¥ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "SageMaker Processing Jobì—ì„œ ì‚¬ìš©í•  ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "input-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…ë ¥ ë°ì´í„°ë¥¼ S3ì— ì—…ë¡œë“œ\n",
    "input_source = sess.upload_data(\n",
    "    './bank-additional/bank-additional-full.csv', \n",
    "    bucket=bucket, \n",
    "    key_prefix=f'{prefix}/input_data'\n",
    ")\n",
    "\n",
    "print(f\"âœ… ì…ë ¥ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ: {input_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "output-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ ê²½ë¡œ ì„¤ì •\n",
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "validation_path = f\"s3://{bucket}/{prefix}/validation\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\"\n",
    "baseline_path = f\"s3://{bucket}/{prefix}/baseline\"\n",
    "\n",
    "print(\"âœ… ì¶œë ¥ ê²½ë¡œ ì„¤ì • ì™„ë£Œ:\")\n",
    "print(f\"   - í›ˆë ¨ ë°ì´í„°: {train_path}\")\n",
    "print(f\"   - ê²€ì¦ ë°ì´í„°: {validation_path}\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_path}\")\n",
    "print(f\"   - ë² ì´ìŠ¤ë¼ì¸: {baseline_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mlflow-experiment",
   "metadata": {},
   "source": [
    "## 4. MLflow ì‹¤í—˜ ì‹œì‘\n",
    "\n",
    "ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •ì„ ì¶”ì í•˜ê¸° ìœ„í•œ MLflow ì‹¤í—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "db64a3e6-4136-4f22-a889-6460e400130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "c6564424-394b-4f40-85e9-57d8fa0ec010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import mlflow\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì„¤ì • (MLflow ì œì™¸)\n",
    "project = Project()\n",
    "role = project.iam_role\n",
    "domain_id = project.domain_id\n",
    "project_id = project.id\n",
    "\n",
    "# MLflow ì§ì ‘ ì„¤ì •\n",
    "\n",
    "print(f\"   - MLflow ì„œë²„: {mlflow_name}\")\n",
    "mlflow.set_tracking_uri(mlflow_arn)\n",
    "\n",
    "# ì‹¤í–‰ ì´ë¦„ ìƒì„±\n",
    "run_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "run_name = f\"data-preprocessing-{run_suffix}\"\n",
    "\n",
    "# MLflow ì‹¤í–‰ ì‹œì‘\n",
    "run_id = mlflow.start_run(\n",
    "    run_name=run_name, \n",
    "    description=\"SageMaker Processingì„ ì‚¬ìš©í•œ ë°ì´í„° ì „ì²˜ë¦¬\"\n",
    ").info.run_id\n",
    "\n",
    "print(f\"âœ… MLflow ì‹¤í–‰ ì‹œì‘: {run_name}\")\n",
    "print(f\"   - ì‹¤í–‰ ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing-job",
   "metadata": {},
   "source": [
    "## 5. SageMaker Processing Job ì‹¤í–‰\n",
    "\n",
    "ì„¤ì •ëœ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ SageMaker Processing Jobìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "processor-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SageMaker Processing Job ì„¤ì •\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "    estimator_cls=SKLearn,\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1, \n",
    "    base_job_name='bank-data-preprocessing',\n",
    "    env={\n",
    "        'MLFLOW_TRACKING_ARN': mlflow_arn,\n",
    "        'MLFLOW_RUN_ID': run_id,\n",
    "        'USER': user_profile_name,\n",
    "        'DOMAIN_ID': domain_id\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âœ… Processing Job í”„ë¡œì„¸ì„œ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "processing-inputs-outputs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…ë ¥ ë° ì¶œë ¥ ì„¤ì •\n",
    "processing_inputs = [\n",
    "    ProcessingInput(\n",
    "        source=input_source, \n",
    "        destination=\"/opt/ml/processing/input\",\n",
    "        s3_input_mode=\"File\",\n",
    "        s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"train_data\", \n",
    "        source=\"/opt/ml/processing/output/train\",\n",
    "        destination=train_path,\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"validation_data\", \n",
    "        source=\"/opt/ml/processing/output/validation\", \n",
    "        destination=validation_path\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"test_data\", \n",
    "        source=\"/opt/ml/processing/output/test\", \n",
    "        destination=test_path\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"baseline_data\", \n",
    "        source=\"/opt/ml/processing/output/baseline\", \n",
    "        destination=baseline_path\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ… ì…ë ¥/ì¶œë ¥ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "run-processing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Processing Job ì‹¤í–‰\n",
    "print(\"ğŸš€ SageMaker Processing Job ì‹œì‘...\")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    inputs=processing_inputs,\n",
    "    code='processing/preprocessing.py',\n",
    "    outputs=processing_outputs,\n",
    "    dependencies=['processing/requirements/requirements.txt'],\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Processing Job ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-verification",
   "metadata": {},
   "source": [
    "## 6. ê²°ê³¼ í™•ì¸\n",
    "\n",
    "ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "verify-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„° í™•ì¸\n",
    "train_data = sess.read_s3_file(\n",
    "    bucket=bucket,\n",
    "    key_prefix=f\"{prefix}/train/train.csv\"\n",
    ")\n",
    "\n",
    "df_train = pd.read_csv(io.StringIO(train_data), header=None)\n",
    "\n",
    "print(\"âœ… ì „ì²˜ë¦¬ ê²°ê³¼ í™•ì¸:\")\n",
    "print(f\"   - í›ˆë ¨ ë°ì´í„° í¬ê¸°: {df_train.shape}\")\n",
    "print(f\"   - ì²« ë²ˆì§¸ ì»¬ëŸ¼ (íƒ€ê²Ÿ): {df_train[0].value_counts()}\")\n",
    "\n",
    "print(\"\\nğŸ“Š í›ˆë ¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "3a022d08-07ab-4d98-894c-92830edbc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ì‹¤í–‰ ì™„ë£Œ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "mlflow.set_tags({\n",
    "    'sagemaker.processing_job': sklearn_processor.latest_job.name,\n",
    "    'sagemaker.domain_id': domain_id,\n",
    "    'sagemaker.project_id': project_id,\n",
    "    'processing.status': 'completed'\n",
    "})\n",
    "\n",
    "# í˜„ì¬ ì‹¤í–‰ ID ì €ì¥\n",
    "current_run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"âœ… MLflow ì‹¤í–‰ ì™„ë£Œ\")\n",
    "print(f\"   - Processing Job: {sklearn_processor.latest_job.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "store-variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë“¤ ì €ì¥\n",
    "%store input_source\n",
    "%store train_path\n",
    "%store validation_path\n",
    "%store test_path\n",
    "%store baseline_path\n",
    "\n",
    "print(\"âœ… ë³€ìˆ˜ ì €ì¥ ì™„ë£Œ\")\n",
    "print(\"\\nğŸ“‹ ì €ì¥ëœ ê²½ë¡œ:\")\n",
    "print(f\"   - ì…ë ¥ ë°ì´í„°: {input_source}\")\n",
    "print(f\"   - í›ˆë ¨ ë°ì´í„°: {train_path}\")\n",
    "print(f\"   - ê²€ì¦ ë°ì´í„°: {validation_path}\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_path}\")\n",
    "print(f\"   - ë² ì´ìŠ¤ë¼ì¸: {baseline_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completion",
   "metadata": {},
   "source": [
    "## âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
    "\n",
    "SageMaker Processing Jobì„ ì‚¬ìš©í•œ ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "### ì™„ë£Œëœ ì‘ì—…\n",
    "- âœ… ì›ë³¸ ë°ì´í„° ì „ì²˜ë¦¬ (íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§, ì›-í•« ì¸ì½”ë”©)\n",
    "- âœ… í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "- âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ S3ì— ì €ì¥\n",
    "- âœ… MLflowë¥¼ í†µí•œ ì‹¤í—˜ ì¶”ì \n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "ì´ì œ `2-training.ipynb` ë…¸íŠ¸ë¶ìœ¼ë¡œ ì§„í–‰í•˜ì—¬ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ìƒì„±ëœ ë°ì´í„°\n",
    "- **í›ˆë ¨ ë°ì´í„°**: ëª¨ë¸ í›ˆë ¨ìš© (70%)\n",
    "- **ê²€ì¦ ë°ì´í„°**: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìš© (20%)\n",
    "- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: ìµœì¢… ëª¨ë¸ í‰ê°€ìš© (10%)\n",
    "- **ë² ì´ìŠ¤ë¼ì¸**: ëª¨ë¸ ëª¨ë‹ˆí„°ë§ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "c8e18297-4dc3-499e-9ffb-7bb295bf9af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
